---
title: "Game 2 – 04"
description: "https://sourcing.games/game-2/game-2-c4cca/"
summary: "Game 2 – 04"
date: 2024-02-27T19:53:11+07:00
draft: false
author: "Hiiruki" # ["Me", "You"] # multiple authors
tags: ["OSINT", "sourcing-games", "game2", "game2-4", "linkedin", "robots.txt"]
canonicalURL: ""
showToc: true
TocOpen: false
TocSide: 'right'  # or 'left'
# weight: 1
# aliases: ["/first"]
hidemeta: false
comments: false
disableHLJS: true # to disable highlightjs
disableShare: true
hideSummary: false
searchHidden: false
ShowReadingTime: true
ShowBreadCrumbs: true
ShowPostNavLinks: true
ShowWordCount: true
ShowRssButtonInSectionTermList: true
# UseHugoToc: true
cover:
    image: "images/cover.webp" # image path/url
    alt: "Cover: Sourcing Games Logo" # alt text
    caption: "" # display caption under cover
    relative: false # when using page bundles set this to true
    hidden: false # only hide on current single page
# editPost:
#     URL: "https://github.com/hiiruki/hiiruki.dev/tree/main/content/writeups/sourcing-games/game2-04/index.md"
#     Text: "Suggest Changes" # edit text
#     appendFilePath: true # to append file path to Edit link
---

## Description

LinkedIn disallows all robots to index some things, and these robots already know that your “keyword for next level” is a part of the e-mail address before @linkedin.com.

## Instructions

Password is the keyword before @linkedin.com

## Solution

The hint is about `robots.txt` file.




We can check the `robots.txt` file of LinkedIn by visiting `https://www.linkedin.com/robots.txt`.


## Flag/Password

<details>
<summary> Show </summary>

``

</details>

## References

- [Introduction to robots.txt](https://developers.google.com/search/docs/crawling-indexing/robots/intro)
- [What is a robots.txt file?](https://moz.com/learn/seo/robotstxt)
- [What is robots.txt? | How a robots.txt file works](https://www.cloudflare.com/learning/bots/what-is-robots-txt/)
- [robots.txt @ Wikipedia](https://en.wikipedia.org/wiki/Robots.txt)
- [The ultimate guide to robots.txt](https://yoast.com/ultimate-guide-robots-txt/)
- [The Web Robots Pages](https://www.robotstxt.org/)
